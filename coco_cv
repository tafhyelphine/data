import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import os
import requests
from concurrent.futures import ThreadPoolExecutor

# --- STEP 1: Manual "Mini COCO" Downloader ---
# Since TFDS crashes Colab, we manually fetch 50 specific images from COCO servers.

data_dir = 'coco_mini_dataset/train/class_0'
os.makedirs(data_dir, exist_ok=True)

# A list of valid COCO Validation image IDs
# (Random selection from val2017)
image_ids = [
    139, 285, 632, 724, 776, 785, 802, 872, 885, 1000,
    1268, 1296, 1353, 1425, 1490, 1503, 1532, 1584, 1675, 1761,
    1818, 1993, 2006, 2148, 2153, 2261, 2299, 2333, 2465, 2473,
    2532, 2685, 2923, 2929, 2953, 3155, 3236, 3255, 3357, 3457,
    3546, 3553, 3661, 3723, 3835, 3845, 3934, 3979, 4134, 4283
]

def download_image(img_id):
    # Formats ID to 12 digits (e.g., 139 -> 000000000139.jpg)
    file_name = f"{img_id:012d}.jpg"
    url = f"http://images.cocodataset.org/val2017/{file_name}"
    save_path = os.path.join(data_dir, file_name)

    if not os.path.exists(save_path):
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                with open(save_path, 'wb') as f:
                    f.write(response.content)
        except:
            pass # Skip if download fails

print(f"Downloading {len(image_ids)} COCO images directly...")
# Download in parallel to be fast
with ThreadPoolExecutor(max_workers=10) as executor:
    executor.map(download_image, image_ids)

print("Download complete. Files in folder:", len(os.listdir(data_dir)))

# --- STEP 2: Load Data using image_dataset_from_directory ---
# This replaces tfds.load

batch_size = 8
img_height = 128
img_width = 128

# Load Training Data (We use the same images for train/val for this tiny demo)
train_ds = tf.keras.utils.image_dataset_from_directory(
    'coco_mini_dataset',
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int' # Uses folder names as labels (we only have class_0)
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    'coco_mini_dataset',
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
    label_mode='int'
)

# c) Plot sample images
plt.figure(figsize=(8, 4))
for images, labels in train_ds.take(1):
    for i in range(min(6, len(images))):
        plt.subplot(2, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.axis("off")
plt.show()

# f) Preprocessing (Normalization)
normalization_layer = layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(tf.data.AUTOTUNE)
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(tf.data.AUTOTUNE)

# g) Build CNN model
# Note: Since we only have 1 folder ('class_0'), the label is always 0.
# We output 1 class with sigmoid or just keep 10 and ignore the rest for the exercise sake.
model = models.Sequential([
    layers.Input(shape=(128, 128, 3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid') # Binary classification (Is it an image? Yes)
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# h) Train
print("\n--- Training Model ---")
history = model.fit(train_ds, validation_data=val_ds, epochs=5)

# d) Augmentation
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
])

# Create augmented dataset
# We need to apply augmentation BEFORE normalization effectively or inside the map
def augment_func(x, y):
    return data_augmentation(x), y

# Reload raw dataset for augmentation path to be clear
raw_train_ds = tf.keras.utils.image_dataset_from_directory(
    'coco_mini_dataset', validation_split=0.2, subset="training", seed=123,
    image_size=(img_height, img_width), batch_size=batch_size, label_mode='int'
)
aug_train_ds = raw_train_ds.map(augment_func).map(lambda x, y: (normalization_layer(x), y))

print("\n--- Training Augmented Model ---")
aug_model = models.clone_model(model)
aug_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
aug_history = aug_model.fit(aug_train_ds, validation_data=val_ds, epochs=5)

# Compare
plt.plot(history.history['accuracy'], label='Original')
plt.plot(aug_history.history['accuracy'], label='Augmented')
plt.legend()
plt.show()
